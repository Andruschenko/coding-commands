---
title: 'NLP - Natural Language Processing'
date: '2019-11-23T00:00:00.000Z'
author: 'Andr√© Kovac'
description: 'A basic example of how to create a DockerFile'
category: 'data'
tags: ['nlp', 'artificial-intelligence', 'machine-learning']
draft: true
---

## Word embeddings

### Definition

Generated by a corpus (a large of text).

### Examples

[spacy.io](https://spacy.io/) offers larger or smaller word embeddings.

[Here for example](https://spacy.io/models/de) are small, medium or large word-embeddings. In the small one just some words won't be in it.

[On this colab](https://colab.research.google.com/drive/1BjRLyBKPfxx4iEV1jWAkBvfBbq2bNY8t#scrollTo=YuI-UHVoyTgw) of a workshop I attended of [responsibly.ai](https://learn.responsibly.ai/word-embedding/) in November 2019.

### Different kinds of word embeddings

#### Bag of words

Each word which occurs in a sentance gets a number which stands for the amount at which it occurs in the sentence.

Pro: Slim, simple representation
Con: Order lost

#### 1-time pad

Pro: Order
Con: No relation between words, a lot of vectors, a lot of zeros!

#### Vectors - relating

Pro: Relation between words is encoded in array of length 300 via the use of a Corpus.

e.g. `Word2Vec`